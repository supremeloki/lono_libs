# Lono Library

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A lightweight and modular Python library for comprehensive machine learning model evaluation and comparison.

## ğŸš€ Overview

`lono_libs` provides a streamlined framework to evaluate various classification and regression models across multiple metrics, allowing for custom metric weighting, performance reporting, and visualization. It emphasizes modularity, extensibility, and ease of use, making it ideal for MLOps workflows and research.

## âœ¨ Features

- **Modular Metric Calculation:** Easily add and manage custom evaluation metrics for both classification and regression
- **Flexible Model Evaluation:** Evaluate a wide range of models with configurable metrics and data splits
- **Weighted Scoring:** Define custom weights for metrics to generate a composite score for model ranking
- **Automated Reporting & Visualization:** Generate performance reports and insightful plots automatically
- **Dependency Injection:** A robust architecture ensuring low coupling and high maintainability

## ğŸš§ Structure

```
lono_libs/
â”œâ”€â”€ .flake8
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_all_tests.py
â”œâ”€â”€ run_evaluation.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.rst
â”‚   â”œâ”€â”€ conf.py
â”‚   â”œâ”€â”€ examples.rst
â”‚   â”œâ”€â”€ index.rst
â”‚   â”œâ”€â”€ make.bat
â”‚   â”œâ”€â”€ Makefile
â”‚   â”œâ”€â”€ metrics.rst
â”‚   â””â”€â”€ quickstart_usage.rst
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ example_correlation.py
â”‚   â”œâ”€â”€ example_multiple_metrics.py
â”‚   â””â”€â”€ quick start.py
â”œâ”€â”€ lono_libs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ best_result.py
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ reporting.py
â”‚   â”œâ”€â”€ summary_reports.py
â”‚   â”œâ”€â”€ unified_runner.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ accuracy.py
â”‚   â”‚   â”œâ”€â”€ balanced_accuracy.py
â”‚   â”‚   â”œâ”€â”€ cohens_kappa.py
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.py
â”‚   â”‚   â”œâ”€â”€ f1_score.py
â”‚   â”‚   â”œâ”€â”€ LogLoss.py
â”‚   â”‚   â”œâ”€â”€ matthews_correlation_coefficient.py
â”‚   â”‚   â”œâ”€â”€ precision.py
â”‚   â”‚   â”œâ”€â”€ recall.py
â”‚   â”‚   â””â”€â”€ roc_auc.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ _base_metric.py
â”‚   â”‚   â”œâ”€â”€ evaluator.py
â”‚   â”‚   â””â”€â”€ scoring.py
â”‚   â””â”€â”€ regression/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ correlation.py
â”‚       â”œâ”€â”€ kurtosis.py
â”‚       â”œâ”€â”€ mae.py
â”‚       â”œâ”€â”€ mse.py
â”‚       â”œâ”€â”€ r2_score.py
â”‚       â””â”€â”€ skewness.py
â””â”€â”€ tests/
    â”œâ”€â”€ Accuracy_mock.py
    â”œâ”€â”€ IMetric_mock.py
    â”œâ”€â”€ UnifiedRunner_mock.py
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_evaluator.py
    â”œâ”€â”€ test_unified_runner.py
    â”œâ”€â”€ classification/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ test_accuracy.py
    â”‚   â”œâ”€â”€ test_balanced_accuracy.py
    â”‚   â”œâ”€â”€ test_cohens_kappa.py
    â”‚   â”œâ”€â”€ test_confusion_matrix.py
    â”‚   â”œâ”€â”€ test_f1_score.py
    â”‚   â”œâ”€â”€ test_log_loss.py
    â”‚   â”œâ”€â”€ test_matthews_correlation_coefficient.py
    â”‚   â”œâ”€â”€ test_precision.py
    â”‚   â”œâ”€â”€ test_recall.py
    â”‚   â””â”€â”€ test_roc_auc.py
    â””â”€â”€ regression/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ test_correlation.py
        â”œâ”€â”€ test_kurtosis.py
        â”œâ”€â”€ test_mae.py
        â”œâ”€â”€ test_mse.py
        â”œâ”€â”€ test_r2_score.py
        â””â”€â”€ test_skewness.py
```
## ğŸ“¦ Installation

### From PyPI
```bash
pip install lono_libs
```

### For Development
```bash
# Clone the repository
git clone https://github.com/supremeloki/lono_libs.git
cd lono_libs

# Create and activate virtual environment
python -m venv .venv
# On Windows
.venv\Scripts\activate
# On Unix/Mac
source .venv/bin/activate

# Install with development dependencies
pip install -e ".[dev,test,docs]"
```

## ğŸ“‹ Requirements

- Python 3.9 or higher
- Required dependencies:
  - numpy >= 1.20
  - pandas >= 1.3
  - scikit-learn >= 1.0
  - matplotlib >= 3.4
  - scipy >= 1.7
  - xgboost >= 1.6
  - lightgbm >= 3.3
  - catboost >= 1.0

## ğŸƒ Quick Start

Here's a simple example of how to use `lono_libs`:

```python
from lono_libs import Evaluator
from lono_libs.classification import accuracy, f1_score
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Create sample data
X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Create evaluator with metrics
evaluator = Evaluator(metrics=[accuracy, f1_score])

# Evaluate model
results = evaluator.evaluate(model, X_test, y_test)
print(results.summary())
```

## ğŸ“Š Available Metrics

### Classification Metrics
- Accuracy
- Precision
- Recall
- F1 Score
- Balanced Accuracy
- Cohen's Kappa
- Matthews Correlation Coefficient
- ROC AUC
- Log Loss
- Confusion Matrix

### Regression Metrics
- Mean Absolute Error (MAE)
- Mean Squared Error (MSE)
- RÂ² Score
- Correlation
- Kurtosis
- Skewness

## ğŸ”§ Usage with UnifiedRunner

For comprehensive model evaluation across multiple algorithms:

```python
from lono_libs import UnifiedRunner

runner = UnifiedRunner(
    output_base_dir="results",
    enable_logging=True,
    enable_visualizations=True
)

# Run evaluation pipeline
results_df, best_models = runner.run_pipeline(
    X_train=X_train,
    X_test=X_test,
    y_train_class=y_train_class,
    y_test_class=y_test_class,
    y_train_reg=None,
    y_test_reg=None,
    preprocessing_config={
        "add_polynomial_features": True,
        "poly_degree": 2,
        "apply_scaler": True
    },
    metrics_to_evaluate=["Accuracy", "F1Score", "Precision", "Recall"]
)
```

## ğŸ§ª Testing

Run the full test suite:
```bash
python run_all_tests.py
```

Or use pytest directly:
```bash
pytest --cov=lono_libs tests/
```

## ğŸ“ Code Quality

We maintain high code quality standards:
- `black` for code formatting
- `ruff` for linting
- `mypy` for type checking

Run quality checks:
```bash
black .
ruff check .
mypy lono_libs
```

## ğŸ“š Documentation

Build documentation locally:
```bash
cd docs
make html
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Kooroush Masoumi** - [kooroushmasoumi@gmail.com](mailto:kooroushmasoumi@gmail.com)

---

â­ Star this repo if you find it useful!